# 혼동행렬(confusion matrix)

|        | predictive |          |          |
| :----: | :--------: | :------: | :------: |
| Actual |            | positive | negative |
|        |  positive  |    TP    |    FN    |
|        |  negative  |    FP    |    TN    |
- Accuracy(정확도) : $(TP + TN)/ (TP+FN+FP+TN)$
- Precision(정밀도): $TP/(TP+FP)$
- Recall(재현도): $TP/(TP+FN)$
- F1-Score: $2*Presicion* Recall/(Precision+Recall)$

## 머신러닝 
- 예제:반도체 공정 데이터를 활용한 공정 이상 예측

# 머신러닝 모델 학습

### 로지스틱 회귀
- 선형 회귀 방식을 분류에 적용한 알고리즘
- 확률에 따라서 분류를 결정
- 주로 이진(0과 1)분류에 사용
- 예측값은 예측 확률을 의미

1) 기본 분류 모델 학습
    ```
    from sklean.linear_model import LogisticRegression
    
    #로지스틱 분류기 모델 class를 가져옵니다
    #max_iter는 로지스틱 알고리즘의 반복 횟수를 정하는 파라미터로 
    본 실습에서는 default값으로 모자르기에 아래와 같이 설정합니다.
	model=LogisticRegression()
	
	#데이터를 학습시킬 때는 fit 함수를 사용
    model.fit(X_train,y_train)
    
    #score함수를 사용하여 모델의 성능을 확인
    print(model.score(X_train,y_train))
    print(model.score(X_test,y_test))
    ```


    ```
    #Logistic Regression의 중요도를 계산
    #가중치 값들의 크기로 판단하기에 .coef_로 해당 값들을 불러옴
    abs_coef = np.abs(model.coef).ravel()
    abs_coef
    ```


    ```
    # bar 형태 그래프로 Logistic Regression의 feature 별 중요도를 
    상위 20개 출력합니다.
    # 상위 20개의 feature 정보를 출력하기 위하여 sorting을 수행하고 
    해당 feature 번호를 LR_imort_x에 저장합니다.
    LR_import_x = [str(i[0]) for i in sorted(enumerate(abs_coef), 
    key=lambda x:x[1], reverse=True)]
    
    plt.bar(LR_import_x[:20], sorted(abs_coef, reverse=True)[:20])
    
    plt.rcParams['figure.figsize'] = (15, 10)
    plt.xlabel('Features')
    plt.ylabel('Weight absolute values')
    plt.show()
    ```

2) 다양한 분류 모델 학습 

    ```
    #xgboost 설치가 잘 안되면 Anaconda Powershell Prompt(anaconda3)
    에서 해봅니다.
    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn.tree import DecisionTreeClassifier
    from sklearn.naive_bayes import GaussianNB
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.svm import SVC
    #여러 모델을 append해서 추가합니다.
    models = []
    models.append(('LDA', LinearDiscriminantAnalysis()))  # LDA 모델
    models.append(('KNN', KNeighborsClassifier()))  # KNN 모델
	models.append(('CART', DecisionTreeClassifier()))  # 의사결정트리 모델
	models.append(('NB', GaussianNB()))  # 가우시안 나이브 베이즈 모델
	models.append(('RF', RandomForestClassifier()))  # 랜덤포레스트 모델
	models.append(('SVM', SVC(gamma='auto')))  # SVM 모델
	for name, model in models:

    # fit으로 학습을 합니다.

    model.fit(X_train, y_train)

  

    # %s와 %f는 문자열 포맷팅으로 %s는 문자열, %f는 숫자형 데이터를 말합니다.
    # 문자열 포맷팅 값은 괄호()안의 값과 대응됩니다.
    # score 함수를 사용하여 모델의 성능을 확인합니다.

    msg = "%s - train_score : %f, test score : %f" % (name,
    model.score(X_train, y_train), model.score(X_test, y_test))

    print(msg)
    ```

# 머신러닝 회귀 알고리즘

### 회귀
- 프랜시스 골턴이 아버지의 키와 아들의 키 사이의 관계를 조사함
- 조사 결과 아버지의 키와 아들의 키 사이의 관계식 기울기가 1보다 작은 2/3로 신장은 세대를 거듭할 수록 평균적인 수치로 회귀한다는 것을 알아내면서 회귀라는 용어가 처음 사용

위의 설명에서 키를 구하는 회귀식과 회귀 분석이 무엇일까?
- **키를 구하는 회귀식** : 변수 간의 함수 관계를 표현하는 식
- **회귀분석** : 회귀식의 관계를 표현하고 분석하는 것

## 회귀분석이란?

- 회귀란 입력과 출력의 상관관계를 찾는 것
### 단순 선형 회귀

- 독립 변수X와 종속변수 Y가 각각 하나이고 임의로 분포한 데이터들을 하나의 직선으로 일반화 시킨 것으로 둘의 관계가 1차 직선인 경우를 단순 선형 회귀라고 한다
 ![[Pasted image 20250422163415.png]]
안녕